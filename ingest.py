from pathlib import Path
import re

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

DATA_DIR = Path("data")
PDF_FILES = sorted(DATA_DIR.glob("*.pdf"))

# ë” ì„¸ë°€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ chunk ì„¤ì • (ê¸°ì¡´ 1000 -> 800)
CHUNK_SIZE = 800
CHUNK_OVERLAP = 160


def extract_year_from_filename(path: Path):
    # sof21.pdf -> 2021, sof2025.pdf -> 2025 ì´ëŸ° ì‹ìœ¼ë¡œ ì²˜ë¦¬
    digits = re.findall(r"\d+", path.stem)
    if not digits:
        return None
    num = digits[-1]
    if len(num) == 2:
        return 2000 + int(num)
    elif len(num) == 4:
        return int(num)
    return None


def detect_chapter(text: str, current_chapter: str | None):
    """
    í˜ì´ì§€ í…ìŠ¤íŠ¸ ì•ˆì—ì„œ Global Economy / Consumer Shifts / Fashion System
    ê°™ì€ ì±•í„° íƒ€ì´í‹€ì´ ë“±ì¥í•˜ë©´ ê·¸ê±¸ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ì±•í„°ë¥¼ ì—…ë°ì´íŠ¸.
    """
    lower = text.lower()
    if "global economy" in lower:
        return "Global Economy"
    if "consumer shifts" in lower:
        return "Consumer Shifts"
    if "fashion system" in lower:
        return "Fashion System"
    # ëª» ì°¾ìœ¼ë©´ ì§ì „ ì±•í„° ìœ ì§€
    return current_chapter


def detect_region(text: str, current_region: str | None):
    """
    ê°„ë‹¨í•œ ë£° ê¸°ë°˜ region íƒœê·¸ ê°ì§€.
    SoFì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ì£¼ìš” ì§€ì—­/êµ­ê°€ ì¤‘ì‹¬ìœ¼ë¡œ íƒœê¹….
    """
    lower = text.lower()

    # êµ­ê°€/ì§€ì—­ í‚¤ì›Œë“œ ë§¤í•‘
    if "japan" in lower:
        return "Japan"
    if "india" in lower:
        return "India"
    if "united states" in lower or "u.s." in lower or " u.s " in lower or " us " in lower:
        return "United States"
    if "china" in lower:
        return "China"
    if "european union" in lower or "eu " in lower or " europe" in lower:
        return "European Union"

    # ëª…ì‹œì ì¸ ì§€ì—­ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ê°’ ìœ ì§€, ì—†ìœ¼ë©´ Global
    return current_region or "Global"


def load_pdfs_with_metadata():
    docs = []
    for pdf_path in PDF_FILES:
        year = extract_year_from_filename(pdf_path)
        print(f"ğŸ“„ Loading {pdf_path.name} (year={year})")

        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load()

        current_chapter = None
        current_region = "Global"
        for page_doc in pages:
            # ì±•í„°/ë¦¬ì „ ê°ì§€ & ë©”íƒ€ë°ì´í„° ë¶€ì—¬
            current_chapter = detect_chapter(page_doc.page_content, current_chapter)
            current_region = detect_region(page_doc.page_content, current_region)

            page_doc.metadata["year"] = year
            page_doc.metadata["chapter"] = current_chapter
            page_doc.metadata["region"] = current_region
            docs.append(page_doc)

    return docs


def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", " ", ""],
    )
    print("âœ‚ï¸ Splitting documents into chunks ...")
    return splitter.split_documents(docs)


def build_vectorstore(splits):
    print("ğŸ§  Loading embedding modelâ€¦")
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    print("ğŸ“¦ Building FAISS vectorstoreâ€¦")
    vs = FAISS.from_documents(splits, embeddings)
    vs.save_local("faiss_index")
    print("âœ… Saved vectorstore to ./faiss_index")


def main():
    if not PDF_FILES:
        print("âŒ data/ í´ë”ì— PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    docs = load_pdfs_with_metadata()
    splits = split_documents(docs)
    build_vectorstore(splits)


if __name__ == "__main__":
    main()
